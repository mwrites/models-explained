{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding\n",
    "\n",
    "What's the difference between valid and same convolutions?\n",
    "\n",
    "What's the output of a kernel of size 5x5?\n",
    "\n",
    "What if you have a kernel of size 5x5 and you want to keep an ouput of size 5x5, what padding should u apply?\n",
    "\n",
    "Why are filters usually odd numbers?\n",
    "\n",
    "## Strides\n",
    "\n",
    "With a 7x7 kernel and a stride 2, padding=1, what's the size of the convolution?\n",
    "\n",
    "### Conv Net\n",
    "\n",
    "What is particuliar about `W * a + b` in a conv net\n",
    "hint: matrix, dot product or element wise mult?\n",
    "\n",
    "You have an input volume that is 63x63x16, and convolve it with 32 filters that are each 7x7, using a stride of 2 and no padding.\n",
    "- Q: What is the output volume? \n",
    "- A: 29x29x32\n",
    "\n",
    "You have an input volume that is 63x63x16, and convolve it with 32 filters that are each 7x7, and stride of 1. You want to use a “same” convolution.\n",
    "- Q: What is the padding?\n",
    "- A: 3\n",
    "\n",
    "You have an input volume that is 66x66x21, and apply max pooling with a stride of 3 and a filter size of 3.\n",
    "- Q: What is the output volume?\n",
    "- A:\n",
    "\n",
    "what do conv net learn? what are the weights exactly?\n",
    "\n",
    "Explain `z = W * a + b` in a convolution layer, what is what?\n",
    "\n",
    "Where or how do we place the ReLU and non linearities in conv net?\n",
    "\n",
    "As we go down the layers, what happens to the channels and what happens to the filters size?\n",
    "\n",
    "\n",
    "### Pooling\n",
    "\n",
    "What are the hyperparams of a pooling layer? What are the weights?\n",
    "\n",
    "\n",
    "### Why Convolutions\n",
    "\n",
    "Give an example of parameter sharing\n",
    "\n",
    "Explain how convolution help with sparsity of connections\n",
    "\n",
    "What's translation invariance, why is it a desirable property?\n",
    "\n",
    "Explain how conv net make it possible to train a neural net with smaller training set\n",
    "A: weight sharing help us reduce the number of parameters and sparsity of connections let us use a smaller number of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1638500\n",
      "hidden_sz 1280\n",
      "filter sz 30\n",
      "output sz 16.0\n",
      "padding 3.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def conv(n, f, p, s):\n",
    "    filter_sz = math.ceil(n + 2 * p - f)\n",
    "    print('filter sz', filter_sz)\n",
    "    output = filter_sz / s + 1\n",
    "    print('output sz', output)\n",
    "    return output\n",
    "\n",
    "def calc_weights_from_neurons(inp_w, channels, hidden_sz):\n",
    "    print(inp_w ** 2 * channels * hidden_sz + hidden_sz)\n",
    "    \n",
    "def calc_hidden(filter_w, channels, n_filters):\n",
    "    print('hidden_sz', filter_w ** 2 * channels *  n_filters + n_filters)\n",
    "\n",
    "def calc_weights_from_filter(inp_w, channels, filter_w, n_filters):\n",
    "    calc_weights_from_neurons(inp_w, channels, filter_w ** 2 * n_filters + filter_w)\n",
    "\n",
    "def padding_for_same_conv(f):\n",
    "    print('padding', (f - 1) / 2)\n",
    "\n",
    "calc_weights_from_neurons(128, 1, 100)\n",
    "calc_hidden(filter_w=3, channels=1, n_filters=128)\n",
    "conv(32, f=2, p=0, s=2)\n",
    "padding_for_same_conv(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "bla = np.zeros((24, 24, 3))\n",
    "bla[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def max_start_index(array_length, kernel_size, stride):\n",
    "    max_index = array_length - kernel_size\n",
    "    max_start_index = (max_index // stride) * stride\n",
    "    return max_start_index\n",
    "\n",
    "max_start_index(19, 3, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical Vision Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Studies\n",
    "\n",
    "what are the three classical paper in vision?\n",
    "\n",
    "what should we remember about lenet5?\n",
    "\n",
    "what should we remember about alexnet?\n",
    "\n",
    "what should we remember about vgg?\n",
    "\n",
    "### Transfer Learning\n",
    "\n",
    "How many layers should you freeze when fine-tuning?\n",
    "\n",
    "\n",
    "### Data Augmentation\n",
    "\n",
    "How can you choose how to do data augmentation?\n",
    "hint: how did alexnet figured out that the model worked better with purplish colors\n",
    "\n",
    "\n",
    "### State Of Computer Vision\n",
    "Classify these tasks in the little to lots of data spectrum:\n",
    "Object detection, image recognition, speech recognition\n",
    "\n",
    "When you have little data, do you need more data engineering or less?\n",
    "\n",
    "What are the two sources of knowledege for a model?\n",
    "A: label data + hand engineered features/network architecture/other components\n",
    "\n",
    "As you get more data, will features or complex network architecture still necessary?\n",
    "A: as we get more data and processing power, models get leaner, for ex transformers and lenet5\n",
    "\n",
    "\n",
    "### How To Do Well On Benchmarks?\n",
    "- Don't start from scatch, if your goal is to learn, it's ok, but if you want to win, you need to gain time and build on top of others\n",
    "- Take open source implementation for reference (don't try to reimplement from paper directly, too many finicky details that you might get wrong or are not even in the paper!)\n",
    "- Ensembling\n",
    "- Test time augmentation\n",
    "- Fine-tuning\n",
    "\n",
    "\n",
    "### Inception Net\n",
    "What's an inception block, how does it help\n",
    "\n",
    "### MobileNet & EfficientNet\n",
    "What's a depthwise separable convolution? What are the pros and cons?\n",
    "\n",
    "In a depthwise convolution each filter convolves with all the colors of the input image, T/F ?\n",
    "\n",
    "What's a bottleneck block? what's the point?\n",
    "\n",
    "What trade-off does efficient net help you with? Hint: there are 3 criteria\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet & Skip Connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what is the activation function of a layer with skip connection?\n",
    "`a[l+2] = ReLu(...?)`\n",
    "\n",
    "what is important for a skip connection to work?\n",
    "hint: valid or same convolution?\n",
    "\n",
    "whats the point of a 1x1 convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
